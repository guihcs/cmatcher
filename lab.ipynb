{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-06T09:42:40.675499205Z",
     "start_time": "2024-02-06T09:42:40.639148960Z"
    }
   },
   "outputs": [],
   "source": [
    "from cmatcher.owl_utils import *\n",
    "from cmatcher.cqa_search import *\n",
    "from cmatcher.eval_utils import *\n",
    "from transformers import AutoTokenizer\n",
    "import dill\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "from accelerate import notebook_launcher\n",
    "\n",
    "from cmatcher.model import *\n",
    "\n",
    "from accelerate import Accelerator\n",
    "import random\n",
    "import wandb\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def parse_arguments():\n",
    "    arg_parser = argparse.ArgumentParser(description='')\n",
    "\n",
    "    arg_parser.add_argument('--sweep', dest='sweep', nargs='?', type=int)\n",
    "\n",
    "    return arg_parser.parse_args()\n",
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = 'false'\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# args = parse_arguments()\n",
    "\n",
    "test_onts = ['cmt', 'conference', 'confOf', 'edas', 'ekaw']\n",
    "language_models = ['BAAI/bge-base-en', 'infgrad/stella-base-en-v2', 'BAAI/bge-large-en-v1.5', 'llmrails/ember-v1',\n",
    "                   'thenlper/gte-large']\n",
    "architectures = ['lm', 'gnn', 'sgnn']\n",
    "lm_grad = ['none', 'grad']\n",
    "pred = ['none', 'pred']\n",
    "dephs = [1, 2, 3, 4]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T10:47:55.742274959Z",
     "start_time": "2024-02-06T10:47:55.694396775Z"
    }
   },
   "id": "983a851392e233b4",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 5)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 19\u001B[0m\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m combs\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(all_combinations()))\n\u001B[0;32m---> 19\u001B[0m test_ont, language_model, architecture, cpred, depth \u001B[38;5;241m=\u001B[39m all_combinations()[\u001B[38;5;241m2\u001B[39m]\n",
      "\u001B[0;31mValueError\u001B[0m: too many values to unpack (expected 5)"
     ]
    }
   ],
   "source": [
    "def all_combinations():\n",
    "    combs = []\n",
    "    for to in test_onts:\n",
    "        for lm in language_models:\n",
    "            for a in architectures:\n",
    "                if a == 'lm':\n",
    "                    combs.append((to, lm, a, 'grad', 'none', 0))\n",
    "                    continue\n",
    "                for g in lm_grad:\n",
    "                    for p in pred:\n",
    "                        for d in dephs:\n",
    "                            combs.append((to, lm, a, g, p, d))\n",
    "\n",
    "    return combs\n",
    "\n",
    "\n",
    "print(len(all_combinations()))\n",
    "\n",
    "test_ont, language_model, architecture, grad, cpred, depth = all_combinations()[2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T10:47:56.844454582Z",
     "start_time": "2024-02-06T10:47:56.829617291Z"
    }
   },
   "id": "b750a65a90424657",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mguihss-cs\u001B[0m (\u001B[33mghss\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.2"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/users/melodi/gsantoss/wandb/run-20240206_104309-jjuh6qys</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/ghss/cmatcher/runs/jjuh6qys' target=\"_blank\">peach-lion-1</a></strong> to <a href='https://wandb.ai/ghss/cmatcher' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/ghss/cmatcher' target=\"_blank\">https://wandb.ai/ghss/cmatcher</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/ghss/cmatcher/runs/jjuh6qys' target=\"_blank\">https://wandb.ai/ghss/cmatcher/runs/jjuh6qys</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ghss/cmatcher/runs/jjuh6qys?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x7fa1cede73d0>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    'test_ont': test_ont,\n",
    "    'learning_rate': 0.00001,\n",
    "    'language_model': language_model,\n",
    "    'architecture': architecture,\n",
    "    'pred': cpred,\n",
    "    'epochs': 5,\n",
    "    'batch_size': 2,\n",
    "    'evm_th': 0.9,\n",
    "    'ev_sim_threshold': 0.8,\n",
    "    'sim_margin': 0.8,\n",
    "    'depth': depth,\n",
    "    'grad': grad\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    project='cmatcher',\n",
    "    config=config,\n",
    "    group=f'{language_model}-{architecture}-{cpred}-{grad}',\n",
    "    settings=wandb.Settings(_disable_stats=True, _disable_meta=True)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T09:43:10.520352586Z",
     "start_time": "2024-02-06T09:43:01.235041979Z"
    }
   },
   "id": "50c71ff3c208cc0a",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from cache.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/101 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "898cebd120f34fc28d2c83743271ac3e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/101 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2c956398f9e4d539f5138a9c9b61767"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from cache.\n"
     ]
    }
   ],
   "source": [
    "ontology_paths = {\n",
    "    'edas.owl': '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/edas.owl',\n",
    "    'ekaw.owl': '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/ekaw.owl',\n",
    "    'confOf.owl': '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/confOf.owl',\n",
    "    'conference.owl': '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/conference.owl',\n",
    "    'cmt.owl': '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/cmt.owl',\n",
    "}\n",
    "\n",
    "cqa_path = '/projets/melodi/gsantoss/data/complex/CQAs'\n",
    "entities_path = '/projets/melodi/gsantoss/data/complex/entities-cqas'\n",
    "\n",
    "if os.path.exists('/projets/melodi/gsantoss/tmp/idata.pkl'):\n",
    "    with open('/projets/melodi/gsantoss/tmp/idata.pkl', 'rb') as f:\n",
    "        train_ont_cqa_subg = dill.load(f)\n",
    "        print('loaded from cache.')\n",
    "else:\n",
    "    with open('/projets/melodi/gsantoss/tmp/idata.pkl', 'wb') as f:\n",
    "        dill.dump(load_entities(entities_path, ontology_paths), f)\n",
    "\n",
    "isg = load_sg(entities_path, ontology_paths)\n",
    "\n",
    "cqas = load_cqas(cqa_path)\n",
    "raw_data = build_raw_data(train_ont_cqa_subg, cqas)\n",
    "\n",
    "test_ont = config['test_ont']\n",
    "\n",
    "if os.path.exists(f'/projets/melodi/gsantoss/tmp/{test_ont}.pkl'):\n",
    "    with open(f'/projets/melodi/gsantoss/tmp/{test_ont}.pkl', 'rb') as f:\n",
    "        ifd, mc, mp, fres = dill.load(f)\n",
    "        print('loaded from cache.')\n",
    "else:\n",
    "    ifd, mc, mp, fres = build_raw_ts(f'/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/{test_ont}.owl',\n",
    "                                     isg[test_ont],\n",
    "                                     workers=4)\n",
    "    with open(f'/projets/melodi/gsantoss/tmp/{test_ont}.pkl', 'wb') as f:\n",
    "        dill.dump((ifd, mc, mp, fres), f)\n",
    "\n",
    "conts_cqa_subg = copy.deepcopy(train_ont_cqa_subg)\n",
    "del conts_cqa_subg[test_ont]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['language_model'])\n",
    "\n",
    "root_entities, graph_data, cq, cqid, caq, cqmask, tor = prepare_eval_dataset(test_ont, cqas, ifd, tokenizer, mc, mp,\n",
    "                                                                             fres)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T09:43:20.872708771Z",
     "start_time": "2024-02-06T09:43:14.237112066Z"
    }
   },
   "id": "ba4a7a2a2951c62c",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/520 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a28de25170804415b5309750b7492baf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First evaluation:\n",
      "bt: 0.80 avgp: 0.06, rec: 0.65, afm: 0.11\n",
      "edas bt: 0.80 avgp: 0.79, rec: 0.25, afm: 0.38\n",
      "confOf bt: 0.80 avgp: 0.86, rec: 0.11, afm: 0.20\n",
      "ekaw bt: 0.80 avgp: 0.57, rec: 0.10, afm: 0.17\n",
      "conference bt: 0.80 avgp: 0.46, rec: 0.14, afm: 0.22\n",
      "ev data: 0.29\n",
      "bt: 0.80 avgp: 0.83, rec: 0.88, afm: 0.85\n",
      "edas bt: 0.60 avgp: 0.50, rec: 0.62, afm: 0.56\n",
      "confOf bt: 0.45 avgp: 0.34, rec: 0.56, afm: 0.42\n",
      "ekaw bt: 0.60 avgp: 0.39, rec: 0.50, afm: 0.44\n",
      "conference bt: 0.60 avgp: 0.34, rec: 0.36, afm: 0.35\n",
      "epoch 0 loss: 0.59, ev: 0.98\n",
      "bt: 0.90 avgp: 0.88, rec: 0.88, afm: 0.88\n",
      "edas bt: 0.45 avgp: 0.42, rec: 0.62, afm: 0.50\n",
      "confOf bt: 0.30 avgp: 0.30, rec: 0.67, afm: 0.41\n",
      "ekaw bt: 0.45 avgp: 0.30, rec: 0.50, afm: 0.38\n",
      "conference bt: 0.45 avgp: 0.29, rec: 0.36, afm: 0.32\n",
      "epoch 1 loss: 0.34, ev: 0.99\n",
      "bt: 0.85 avgp: 0.88, rec: 0.88, afm: 0.88\n",
      "edas bt: 0.60 avgp: 0.63, rec: 0.62, afm: 0.63\n",
      "confOf bt: 0.35 avgp: 0.33, rec: 0.67, afm: 0.45\n",
      "ekaw bt: 0.55 avgp: 0.28, rec: 0.50, afm: 0.36\n",
      "conference bt: 0.40 avgp: 0.25, rec: 0.36, afm: 0.29\n",
      "epoch 2 loss: 0.33, ev: 1.00\n",
      "bt: 0.85 avgp: 0.83, rec: 0.88, afm: 0.85\n",
      "edas bt: 0.45 avgp: 0.50, rec: 0.88, afm: 0.63\n",
      "confOf bt: 0.65 avgp: 0.45, rec: 0.44, afm: 0.45\n",
      "ekaw bt: 0.55 avgp: 0.28, rec: 0.50, afm: 0.36\n",
      "conference bt: 0.45 avgp: 0.37, rec: 0.36, afm: 0.36\n",
      "epoch 3 loss: 0.32, ev: 1.00\n",
      "bt: 0.90 avgp: 0.88, rec: 0.88, afm: 0.88\n",
      "edas bt: 0.80 avgp: 0.75, rec: 0.62, afm: 0.68\n",
      "confOf bt: 0.40 avgp: 0.47, rec: 0.67, afm: 0.55\n",
      "ekaw bt: 0.80 avgp: 0.41, rec: 0.30, afm: 0.35\n",
      "conference bt: 0.50 avgp: 0.37, rec: 0.29, afm: 0.32\n",
      "epoch 4 loss: 0.30, ev: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Ensure read and write access to run files dir: /users/melodi/gsantoss/wandb/run-20240206_104309-jjuh6qys/files, control this via the WANDB_DIR env var. See https://docs.wandb.ai/guides/track/environment-variables\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b86b6072f2d9433792624c18c2e069e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>each/confOf-afm</td><td>▁▅▅▆▆█</td></tr><tr><td>each/confOf-avgp</td><td>█▁▁▁▃▃</td></tr><tr><td>each/confOf-bt</td><td>█▃▁▂▆▂</td></tr><tr><td>each/confOf-rec</td><td>▁▇██▅█</td></tr><tr><td>each/conference-afm</td><td>▁▇▆▅█▆</td></tr><tr><td>each/conference-avgp</td><td>█▄▂▁▅▅</td></tr><tr><td>each/conference-bt</td><td>█▅▂▁▂▃</td></tr><tr><td>each/conference-rec</td><td>▁████▆</td></tr><tr><td>each/edas-afm</td><td>▁▅▄▇▇█</td></tr><tr><td>each/edas-avgp</td><td>█▃▁▅▂▇</td></tr><tr><td>each/edas-bt</td><td>█▄▁▄▁█</td></tr><tr><td>each/edas-rec</td><td>▁▅▅▅█▅</td></tr><tr><td>each/ekaw-afm</td><td>▁█▆▆▆▆</td></tr><tr><td>each/ekaw-avgp</td><td>█▄▂▁▁▄</td></tr><tr><td>each/ekaw-bt</td><td>█▄▁▃▃█</td></tr><tr><td>each/ekaw-rec</td><td>▁████▅</td></tr><tr><td>global/acc</td><td>▁▁▅▅██████</td></tr><tr><td>global/afm</td><td>▁█████</td></tr><tr><td>global/avgp</td><td>▁▇██▇█</td></tr><tr><td>global/bt</td><td>▁▁█▅▅█</td></tr><tr><td>global/gafm</td><td>▁▇▆▇▇█</td></tr><tr><td>global/gavgp</td><td>█▂▁▂▂▅</td></tr><tr><td>global/grec</td><td>▁▇███▇</td></tr><tr><td>global/loss</td><td>██▂▂▂▂▁▁▁▁</td></tr><tr><td>global/rec</td><td>▁█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>each/confOf-afm</td><td>0.55072</td></tr><tr><td>each/confOf-avgp</td><td>0.46914</td></tr><tr><td>each/confOf-bt</td><td>0.4</td></tr><tr><td>each/confOf-rec</td><td>0.66667</td></tr><tr><td>each/conference-afm</td><td>0.32403</td></tr><tr><td>each/conference-avgp</td><td>0.37421</td></tr><tr><td>each/conference-bt</td><td>0.5</td></tr><tr><td>each/conference-rec</td><td>0.28571</td></tr><tr><td>each/edas-afm</td><td>0.68296</td></tr><tr><td>each/edas-avgp</td><td>0.75278</td></tr><tr><td>each/edas-bt</td><td>0.8</td></tr><tr><td>each/edas-rec</td><td>0.625</td></tr><tr><td>each/ekaw-afm</td><td>0.34528</td></tr><tr><td>each/ekaw-avgp</td><td>0.40667</td></tr><tr><td>each/ekaw-bt</td><td>0.8</td></tr><tr><td>each/ekaw-rec</td><td>0.3</td></tr><tr><td>global/acc</td><td>1.0</td></tr><tr><td>global/afm</td><td>0.88366</td></tr><tr><td>global/avgp</td><td>0.88497</td></tr><tr><td>global/bt</td><td>0.9</td></tr><tr><td>global/gafm</td><td>0.47575</td></tr><tr><td>global/gavgp</td><td>0.5007</td></tr><tr><td>global/grec</td><td>0.46935</td></tr><tr><td>global/loss</td><td>0.29917</td></tr><tr><td>global/rec</td><td>0.88235</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">peach-lion-1</strong> at: <a href='https://wandb.ai/ghss/cmatcher/runs/jjuh6qys' target=\"_blank\">https://wandb.ai/ghss/cmatcher/runs/jjuh6qys</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20240206_104309-jjuh6qys/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_function(config, model, root_entities, graph_data, cq, cqid, res, caq, cqmask, tor):\n",
    "    accelerator = Accelerator()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    lh = []\n",
    "    evh = []\n",
    "    epochs = config['epochs']\n",
    "    batch_size = config['batch_size']\n",
    "    progress = None\n",
    "\n",
    "    triplet_loss = nn.TripletMarginWithDistanceLoss(\n",
    "        distance_function=lambda x, y: 1.0 - torch.cosine_similarity(x, y), margin=config['sim_margin'])\n",
    "\n",
    "    dataset = CQADataset(tokenizer, conts_cqa_subg, raw_data[test_ont], filter_bn=False)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    cqloader = DataLoader(cqid, batch_size=batch_size, shuffle=False)\n",
    "    acqloader = [DataLoader(a, batch_size=batch_size, shuffle=False) for a in caq]\n",
    "    graph_loader = DataLoader(graph_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model, optimizer, loader, cqloader, graph_loader, *acqloader = accelerator.prepare(model, optimizer, loader,\n",
    "                                                                                       cqloader, graph_loader,\n",
    "                                                                                       *acqloader)\n",
    "    model.find_unused_parameters = False\n",
    "    if not progress and accelerator.is_main_process:\n",
    "        progress = tqdm(total=epochs * len(loader))\n",
    "\n",
    "    accelerator.print('First evaluation:')\n",
    "    eval_test(accelerator, model, cqloader, graph_loader, cq, root_entities, res, acqloader, cqmask, tor)\n",
    "\n",
    "    accelerator.print(f'ev data: {evm(accelerator, model, dataset, th=config[\"ev_sim_threshold\"]):.2f}')\n",
    "\n",
    "    for e in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        el = []\n",
    "        for batch in loader:\n",
    "            with accelerator.accumulate(model):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                cqs, sbgs, nsbg = model(cqa=batch.cqs, positive_sbg=(batch.x_sf, batch.x_s,\n",
    "                                                                     batch.edge_index_s, batch.edge_feat_sf,\n",
    "                                                                     batch.edge_feat_s),\n",
    "                                        negative_sbg=(batch.x_nf, batch.x_n,\n",
    "                                                      batch.edge_index_n, batch.edge_feat_nf, batch.edge_feat_n))\n",
    "\n",
    "                isbgs = sbgs[batch.rsi]\n",
    "                isbgn = nsbg[batch.rni]\n",
    "\n",
    "                loss = triplet_loss(cqs, isbgs, isbgn)\n",
    "                el.append(accelerator.gather_for_metrics(loss.detach()))\n",
    "                accelerator.backward(loss)\n",
    "\n",
    "                optimizer.step()\n",
    "                if accelerator.is_main_process:\n",
    "                    progress.update(1)\n",
    "\n",
    "        lh.append(torch.stack(el).mean().item())\n",
    "\n",
    "        evh.append(evm(accelerator, model, dataset, th=config[\"ev_sim_threshold\"]))\n",
    "        eval_test(accelerator, model, cqloader, graph_loader, cq, root_entities, res, acqloader, cqmask, tor)\n",
    "        accelerator.print(f'epoch {e} loss: {lh[-1]:.2f}, ev: {evh[-1]:.2f}')\n",
    "        wandb.log({'global/acc': evh[-1], 'global/loss': lh[-1]})\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        progress.close()\n",
    "\n",
    "\n",
    "model = Model(config['language_model'], d=config['depth'], lm_grad=config['grad'] == 'grad')\n",
    "notebook_launcher(train_function, (config, model, root_entities, graph_data, cq, cqid, fres, caq, cqmask, tor), num_processes=2)\n",
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T10:32:11.938792001Z",
     "start_time": "2024-02-06T09:43:59.267050834Z"
    }
   },
   "id": "a585612ff0de1a24",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f4ae59c93f59341f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "myenv",
   "language": "python",
   "display_name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
