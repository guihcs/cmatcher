{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T16:12:52.421473Z",
     "start_time": "2024-05-07T16:11:44.548372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = 'false'\n",
    "os.environ[\"WANDB_DIR\"] = '/projets/melodi/gsantoss/wandbt'\n",
    "\n",
    "from cmatcher.owl_utils import *\n",
    "from cmatcher.cqa_search import *\n",
    "from cmatcher.eval_utils import *\n",
    "from transformers import AutoTokenizer\n",
    "import dill\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import tqdm\n",
    "from cmatcher.model import *\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import wandb\n",
    "\n",
    "import argparse\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)"
   ],
   "id": "e8e16cb874b88929",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T16:24:43.542088Z",
     "start_time": "2024-05-07T16:24:38.732960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_arguments():\n",
    "    arg_parser = argparse.ArgumentParser(description='')\n",
    "\n",
    "    arg_parser.add_argument('--sweep', dest='sweep', nargs='?', type=int)\n",
    "\n",
    "    return arg_parser.parse_args()\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "# args = parse_arguments()\n",
    "\n",
    "test_onts = ['cmt', 'conference', 'confOf', 'edas', 'ekaw']\n",
    "language_models = ['BAAI/bge-base-en', 'infgrad/stella-base-en-v2', 'BAAI/bge-large-en-v1.5', 'llmrails/ember-v1',\n",
    "                   'thenlper/gte-large']\n",
    "architectures = ['lm', 'gnn', 'sgnn']\n",
    "lm_grad = ['none', 'grad']\n",
    "pred = ['none', 'pred']\n",
    "dephs = [1, 2, 3, 4]\n",
    "\n",
    "\n",
    "def all_combinations():\n",
    "    combs = []\n",
    "    for to in test_onts:\n",
    "        for lm in language_models:\n",
    "            for a in architectures:\n",
    "                if a == 'lm':\n",
    "                    combs.append((to, lm, a, 'grad', 'none', 0))\n",
    "                    continue\n",
    "                for g in lm_grad:\n",
    "                    for p in pred:\n",
    "                        for d in dephs:\n",
    "                            combs.append((to, lm, a, g, p, d))\n",
    "\n",
    "    return combs\n",
    "\n",
    "\n",
    "# test_ont, language_model, architecture, grad, cpred, depth = all_combinations()[args.sweep]\n",
    "# test_ont, language_model, architecture, grad, cpred, depth = all_combinations()[0]\n",
    "\n",
    "# config = {\n",
    "#     'test_ont': test_ont,\n",
    "#     'learning_rate': 0.00001,\n",
    "#     'language_model': language_model,\n",
    "#     'architecture': arc        print(batch)\n",
    "#     'pred': cpred,\n",
    "#     'epochs': 5,\n",
    "#     'batch_size': 2,\n",
    "#     'evm_th': 0.9,\n",
    "#     'ev_sim_threshold': 0.8,\n",
    "#     'sim_margin': 0.8,\n",
    "#     'depth': depth,\n",
    "#     'grad': grad\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "config = {\n",
    "    'test_ont': 'edas',\n",
    "    'learning_rate': 0.00001,\n",
    "    'language_model': 'google-bert/bert-base-uncased',\n",
    "    'architecture': 'gnn',\n",
    "    'pred': 'none',\n",
    "    'epochs': 5,\n",
    "    'batch_size': 2,\n",
    "    'evm_th': 0.9,\n",
    "    'ev_sim_threshold': 0.8,\n",
    "    'sim_margin': 0.8,\n",
    "    'depth': 2,\n",
    "    'grad': 'grad'\n",
    "}\n",
    "\n",
    "cqa_path = '/projets/melodi/gsantoss/data/complex/CQAs'\n",
    "entities_path = '/projets/melodi/gsantoss/data/complex/entities-cqas'\n",
    "temp_path = '/projets/melodi/gsantoss/tmp'\n",
    "onts_path = '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts'\n",
    "\n",
    "\n",
    "# cqa_path = '/home/guilherme/Documents/complex/CQAs'\n",
    "# entities_path = '/home/guilherme/Documents/complex/entities-cqas'\n",
    "# temp_path = '/tmp'\n",
    "# onts_path = '/home/guilherme/Documents/kg/conference'\n",
    "\n",
    "\n",
    "\n",
    "ontology_paths = {\n",
    "    'edas.owl': f'{onts_path}/edas.owl',\n",
    "    'ekaw.owl': f'{onts_path}/ekaw.owl',\n",
    "    'confOf.owl': f'{onts_path}/confOf.owl',\n",
    "    'conference.owl': f'{onts_path}/conference.owl',\n",
    "    'cmt.owl': f'{onts_path}/cmt.owl',\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_ont = config['test_ont']\n",
    "\n",
    "\n",
    "cqas = load_cqas(cqa_path)\n",
    "\n",
    "\n",
    "if os.path.exists(f'{temp_path}/idata.pkl'):\n",
    "    with open(f'{temp_path}/idata.pkl', 'rb') as f:\n",
    "        train_ont_cqa_subg = dill.load(f)\n",
    "        print('loaded from cache.')\n",
    "else:\n",
    "    with open(f'{temp_path}/idata.pkl', 'wb') as f:\n",
    "        train_ont_cqa_subg = load_entities(entities_path, ontology_paths)\n",
    "        dill.dump(load_entities(entities_path, ontology_paths), f)\n",
    "        \n",
    "\n",
    "\n",
    "class RawDataset:\n",
    "    \n",
    "    def __init__(self, temp_path, test_ont, entities_path, ontology_paths, onts_path, use_cache=True):\n",
    "        \n",
    "        if os.path.exists(f'{temp_path}/{test_ont}.pkl') and use_cache:\n",
    "            with open(f'{temp_path}/{test_ont}.pkl', 'rb') as f:\n",
    "                ifd, mc, mp, fres = dill.load(f)\n",
    "                print('loaded from cache.')\n",
    "        else:\n",
    "            \n",
    "            isg = load_sg(entities_path, ontology_paths)\n",
    "            ifd, mc, mp, fres = build_raw_ts(f'{onts_path}/{test_ont}.owl', isg[test_ont], workers=4)\n",
    "            with open(f'{temp_path}/{test_ont}.pkl', 'wb') as f:\n",
    "                dill.dump((ifd, mc, mp, fres), f)\n",
    "        \n",
    "        \n",
    "        self.ifd = ifd\n",
    "        self.mc = mc\n",
    "        self.mp = mp\n",
    "        self.fres = fres\n",
    "        \n",
    "        \n",
    "raw_dataset = RawDataset(temp_path, test_ont, entities_path, ontology_paths, onts_path)\n",
    "        \n",
    "ifd = raw_dataset.ifd\n",
    "mc = raw_dataset.mc\n",
    "mp = raw_dataset.mp\n",
    "fres = raw_dataset.fres\n",
    "\n",
    "conts_cqa_subg = copy.deepcopy(train_ont_cqa_subg)\n",
    "del conts_cqa_subg[test_ont]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['language_model'])\n",
    "\n",
    "root_entities, graph_data, cq, cqid, caq, cqmask, tor = prepare_eval_dataset(test_ont, cqas, ifd, tokenizer, mc, mp, fres)\n",
    "\n",
    "wandb.init(\n",
    "    project='cmatcher',\n",
    "    config=config,\n",
    "    group=f'{config[\"language_model\"]}-{config[\"architecture\"]}-{config[\"pred\"]}-{config[\"grad\"]}',\n",
    "    settings=wandb.Settings(_disable_stats=True, _disable_meta=True)\n",
    ")\n",
    "\n",
    "print(config)\n",
    "\n",
    "# %%\n",
    "print('start training')\n",
    "\n",
    "# %%\n",
    "model = Model(config['language_model'], d=config['depth'], lm_grad=config['grad'] == 'grad')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "lh = []\n",
    "evh = []\n",
    "epochs = config['epochs']\n",
    "batch_size = config['batch_size']\n",
    "progress = None\n",
    "\n",
    "triplet_loss = nn.TripletMarginWithDistanceLoss(\n",
    "    distance_function=lambda x, y: 1.0 - torch.cosine_similarity(x, y, dim=1), margin=config['sim_margin'])\n",
    "\n",
    "print('build datasets')\n",
    "\n",
    "del train_ont_cqa_subg['confOf']\n",
    "# del train_ont_cqa_subg['conference']\n",
    "# del train_ont_cqa_subg['edas']\n",
    "del train_ont_cqa_subg['ekaw']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "raw_data = build_raw_data(train_ont_cqa_subg, cqas)\n",
    "\n",
    "\n",
    "dataset = CQADataset(tokenizer, conts_cqa_subg, raw_data[test_ont], filter_bn=False)\n",
    "loader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "cqloader = DataLoader(cqid, batch_size=batch_size, shuffle=False)\n",
    "acqloader = [DataLoader(a, batch_size=batch_size, shuffle=False) for a in caq]\n",
    "graph_loader = DataLoader(graph_data, batch_size=batch_size, shuffle=False)\n"
   ],
   "id": "41cdb5a957ae13fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 1131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "683a783f75da45cda687f0f63e1acfdd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from cache.\n",
      "loaded from cache.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/projets/melodi/gsantoss/wandbt/wandb/run-20240507_182441-covn5h9f</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ghss/cmatcher/runs/covn5h9f' target=\"_blank\">dandy-sponge-511</a></strong> to <a href='https://wandb.ai/ghss/cmatcher' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/ghss/cmatcher' target=\"_blank\">https://wandb.ai/ghss/cmatcher</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/ghss/cmatcher/runs/covn5h9f' target=\"_blank\">https://wandb.ai/ghss/cmatcher/runs/covn5h9f</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_ont': 'edas', 'learning_rate': 1e-05, 'language_model': 'google-bert/bert-base-uncased', 'architecture': 'gnn', 'pred': 'none', 'epochs': 5, 'batch_size': 2, 'evm_th': 0.9, 'ev_sim_threshold': 0.8, 'sim_margin': 0.8, 'depth': 2, 'grad': 'grad'}\n",
      "start training\n",
      "build datasets\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T16:24:43.547132Z",
     "start_time": "2024-05-07T16:24:43.543403Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(dataset))",
   "id": "7cdde35d8bfcc9f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T18:18:36.595624Z",
     "start_time": "2024-05-07T16:24:44.807651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print('data prepared')\n",
    "model.find_unused_parameters = False\n",
    "if not progress:\n",
    "    progress = tqdm(total=epochs * len(loader))\n",
    "\n",
    "print('start training')\n",
    "# evh.append(evm(model, dataset, device, th=config[\"ev_sim_threshold\"]))\n",
    "# eval_test(model, device, cqloader, graph_loader, cq, root_entities, fres, acqloader, cqmask, tor)\n",
    "# wandb.log({'global/acc': evh[-1]})\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    el = []\n",
    "    for batch in loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cqs, sbgs, nsbg = model(cqa=batch.cqs.to(device), positive_sbg=(batch.x_sf.to(device), batch.x_s.to(device),\n",
    "                                                                     batch.edge_index_s.to(device),\n",
    "                                                                     batch.edge_feat_sf.to(device),\n",
    "                                                                     batch.edge_feat_s.to(device)),\n",
    "                                negative_sbg=(batch.x_nf.to(device), batch.x_n.to(device),\n",
    "                                              batch.edge_index_n.to(device), batch.edge_feat_nf.to(device),\n",
    "                                              batch.edge_feat_n.to(device)))\n",
    "        \n",
    "\n",
    "        isbgs = sbgs[batch.rsi]\n",
    "        isbgn = nsbg[batch.rni]\n",
    "\n",
    "\n",
    "        loss = triplet_loss(cqs, isbgs, isbgn)\n",
    "        el.append(loss.detach())\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        progress.update(1)\n",
    "\n",
    "\n",
    "    lh.append(torch.stack(el).mean().item())\n",
    "\n",
    "    evh.append(evm(model, dataset, device, th=config[\"ev_sim_threshold\"]))\n",
    "    eval_test(model, device, cqloader, graph_loader, cq, root_entities, fres, acqloader, cqmask, tor)\n",
    "    wandb.log({'global/acc': evh[-1], 'global/loss': lh[-1]})\n",
    "\n",
    "progress.close()\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "torch.save(model.state_dict(), f'{temp_path}/model.pt')\n",
    "# %%"
   ],
   "id": "eb440d1eceed7191",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data prepared\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/820 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d1ec78e89bef4ce78f6123aee466ffd3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "begin evm\n",
      "end evm\n",
      "begin evm\n",
      "end evm\n",
      "begin evm\n",
      "end evm\n",
      "begin evm\n",
      "end evm\n",
      "begin evm\n",
      "end evm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Ensure read and write access to run files dir: /projets/melodi/gsantoss/wandbt/wandb/run-20240507_182441-covn5h9f/files, control this via the WANDB_DIR env var. See https://docs.wandb.ai/guides/track/environment-variables\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "541125666081455e9d7bf4474e35d0e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>each/cmt-afm</td><td>▅▄█▁▆</td></tr><tr><td>each/cmt-avgp</td><td>▃▂▃▁█</td></tr><tr><td>each/cmt-bt</td><td>▁▅▇██</td></tr><tr><td>each/cmt-rec</td><td>▂█▇▂▁</td></tr><tr><td>each/confOf-afm</td><td>▃▁▂█▁</td></tr><tr><td>each/confOf-avgp</td><td>▂▁▁█▁</td></tr><tr><td>each/confOf-bt</td><td>▄▆▁█▂</td></tr><tr><td>each/confOf-rec</td><td>▅█▁▅▅</td></tr><tr><td>each/conference-afm</td><td>█▃█▁▆</td></tr><tr><td>each/conference-avgp</td><td>█▃█▁▄</td></tr><tr><td>each/conference-bt</td><td>▁▇██▇</td></tr><tr><td>each/conference-rec</td><td>█▁███</td></tr><tr><td>each/ekaw-afm</td><td>▅▄▇█▁</td></tr><tr><td>each/ekaw-avgp</td><td>▃▂█▂▁</td></tr><tr><td>each/ekaw-bt</td><td>▅▆▂█▁</td></tr><tr><td>each/ekaw-rec</td><td>▁▂▁█▁</td></tr><tr><td>global/acc</td><td>▁▅▆█▇</td></tr><tr><td>global/afm</td><td>██▁▁█</td></tr><tr><td>global/avgp</td><td>▇█▃▁▅</td></tr><tr><td>global/bt</td><td>▁▇█▇▆</td></tr><tr><td>global/gafm</td><td>▆▁█▄▂</td></tr><tr><td>global/gavgp</td><td>▅▁█▄▆</td></tr><tr><td>global/grec</td><td>▂█▅▇▁</td></tr><tr><td>global/loss</td><td>█▁▁▁▁</td></tr><tr><td>global/rec</td><td>▃▃▁█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>each/cmt-afm</td><td>0.16441</td></tr><tr><td>each/cmt-avgp</td><td>0.46193</td></tr><tr><td>each/cmt-bt</td><td>0.85</td></tr><tr><td>each/cmt-rec</td><td>0.1</td></tr><tr><td>each/confOf-afm</td><td>0.01214</td></tr><tr><td>each/confOf-avgp</td><td>0.0063</td></tr><tr><td>each/confOf-bt</td><td>0.35</td></tr><tr><td>each/confOf-rec</td><td>0.16667</td></tr><tr><td>each/conference-afm</td><td>0.13956</td></tr><tr><td>each/conference-avgp</td><td>0.12771</td></tr><tr><td>each/conference-bt</td><td>0.8</td></tr><tr><td>each/conference-rec</td><td>0.15385</td></tr><tr><td>each/ekaw-afm</td><td>0.01852</td></tr><tr><td>each/ekaw-avgp</td><td>0.01075</td></tr><tr><td>each/ekaw-bt</td><td>0.35</td></tr><tr><td>each/ekaw-rec</td><td>0.06667</td></tr><tr><td>global/acc</td><td>0.7439</td></tr><tr><td>global/afm</td><td>0.16396</td></tr><tr><td>global/avgp</td><td>0.10544</td></tr><tr><td>global/bt</td><td>0.85</td></tr><tr><td>global/gafm</td><td>0.08366</td></tr><tr><td>global/gavgp</td><td>0.15167</td></tr><tr><td>global/grec</td><td>0.12179</td></tr><tr><td>global/loss</td><td>0.33939</td></tr><tr><td>global/rec</td><td>0.36842</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dandy-sponge-511</strong> at: <a href='https://wandb.ai/ghss/cmatcher/runs/covn5h9f' target=\"_blank\">https://wandb.ai/ghss/cmatcher/runs/covn5h9f</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>/projets/melodi/gsantoss/wandbt/wandb/run-20240507_182441-covn5h9f/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T18:18:36.600077Z",
     "start_time": "2024-05-07T18:18:36.597219Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4c01ff1ccae9b1c7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8425790f3da3aadc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "myenv",
   "language": "python",
   "display_name": "Python (myenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
