{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = 'false'\n",
    "os.environ[\"WANDB_DIR\"] = '/projets/melodi/gsantoss/wandbt'\n",
    "\n",
    "from cmatcher.owl_utils import *\n",
    "from cmatcher.cqa_search import *\n",
    "from cmatcher.eval_utils import *\n",
    "from transformers import AutoTokenizer\n",
    "import dill\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import tqdm\n",
    "from cmatcher.model import *\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import wandb\n",
    "\n",
    "import argparse\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T16:22:11.460481Z",
     "start_time": "2024-03-11T16:22:06.136939Z"
    }
   },
   "id": "5c69491a5ea65e9c",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "def parse_arguments():\n",
    "    arg_parser = argparse.ArgumentParser(description='')\n",
    "\n",
    "    arg_parser.add_argument('--sweep', dest='sweep', nargs='?', type=int)\n",
    "\n",
    "    return arg_parser.parse_args()\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "# args = parse_arguments()\n",
    "\n",
    "test_onts = ['cmt', 'conference', 'confOf', 'edas', 'ekaw']\n",
    "language_models = ['BAAI/bge-base-en', 'infgrad/stella-base-en-v2', 'BAAI/bge-large-en-v1.5', 'llmrails/ember-v1',\n",
    "                   'thenlper/gte-large']\n",
    "architectures = ['lm', 'gnn', 'sgnn']\n",
    "lm_grad = ['none', 'grad']\n",
    "pred = ['none', 'pred']\n",
    "dephs = [1, 2, 3, 4]\n",
    "\n",
    "\n",
    "def all_combinations():\n",
    "    combs = []\n",
    "    for to in test_onts:\n",
    "        for lm in language_models:\n",
    "            for a in architectures:\n",
    "                if a == 'lm':\n",
    "                    combs.append((to, lm, a, 'grad', 'none', 0))\n",
    "                    continue\n",
    "                for g in lm_grad:\n",
    "                    for p in pred:\n",
    "                        for d in dephs:\n",
    "                            combs.append((to, lm, a, g, p, d))\n",
    "\n",
    "    return combs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T16:22:11.467254Z",
     "start_time": "2024-03-11T16:22:11.462068Z"
    }
   },
   "id": "bba67ac72231b6d3",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# test_ont, language_model, architecture, grad, cpred, depth = all_combinations()[args.sweep]\n",
    "# # test_ont, language_model, architecture, grad, cpred, depth = all_combinations()[0]\n",
    "# \n",
    "# config = {\n",
    "#     'test_ont': test_ont,\n",
    "#     'learning_rate': 0.00001,\n",
    "#     'language_model': language_model,\n",
    "#     'architecture': architecture,\n",
    "#     'pred': cpred,\n",
    "#     'epochs': 5,\n",
    "#     'batch_size': 2,\n",
    "#     'evm_th': 0.9,\n",
    "#     'ev_sim_threshold': 0.8,\n",
    "#     'sim_margin': 0.8,\n",
    "#     'depth': depth,\n",
    "#     'grad': grad\n",
    "# }\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T16:22:11.483917Z",
     "start_time": "2024-03-11T16:22:11.468388Z"
    }
   },
   "id": "7746b2c7236b5bfd",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "config = {\n",
    "    'test_ont': 'confOf',\n",
    "    'learning_rate': 0.00001,\n",
    "    'language_model': 'BAAI/bge-base-en',\n",
    "    'architecture': 'lm',\n",
    "    'pred': 'none',\n",
    "    'epochs': 5,\n",
    "    'batch_size': 2,\n",
    "    'evm_th': 0.9,\n",
    "    'ev_sim_threshold': 0.8,\n",
    "    'sim_margin': 0.8,\n",
    "    'depth': 0,\n",
    "    'grad': 'grad'\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T16:22:11.535050Z",
     "start_time": "2024-03-11T16:22:11.532206Z"
    }
   },
   "id": "c07060d37bcdadb1",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from cache.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/101 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "509bc80568754678bec653d6a2128081"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/101 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "76f6634d41624c02aa9e1130a35b560d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from cache.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mguihss-cs\u001B[0m (\u001B[33mghss\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.3"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/projets/melodi/gsantoss/wandbt/wandb/run-20240311_172345-dl4lvsb6</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/ghss/tcmatcher/runs/dl4lvsb6' target=\"_blank\">usual-pond-3</a></strong> to <a href='https://wandb.ai/ghss/tcmatcher' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/ghss/tcmatcher' target=\"_blank\">https://wandb.ai/ghss/tcmatcher</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/ghss/tcmatcher/runs/dl4lvsb6' target=\"_blank\">https://wandb.ai/ghss/tcmatcher/runs/dl4lvsb6</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_ont': 'confOf', 'learning_rate': 1e-05, 'language_model': 'BAAI/bge-base-en', 'architecture': 'lm', 'pred': 'none', 'epochs': 5, 'batch_size': 2, 'evm_th': 0.9, 'ev_sim_threshold': 0.8, 'sim_margin': 0.8, 'depth': 0, 'grad': 'grad'}\n",
      "start training\n",
      "build datasets\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 103\u001B[0m\n\u001B[1;32m     99\u001B[0m triplet_loss \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mTripletMarginWithDistanceLoss(\n\u001B[1;32m    100\u001B[0m     distance_function\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x, y: \u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m-\u001B[39m torch\u001B[38;5;241m.\u001B[39mcosine_similarity(x, y), margin\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msim_margin\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbuild datasets\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 103\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mCQADataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconts_cqa_subg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mraw_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtest_ont\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilter_bn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflat_bn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    104\u001B[0m loader \u001B[38;5;241m=\u001B[39m DataLoader(dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size)\n\u001B[1;32m    106\u001B[0m cqloader \u001B[38;5;241m=\u001B[39m DataLoader(cqid, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/cmatcher/cqa_search.py:169\u001B[0m, in \u001B[0;36mCQADataset.__init__\u001B[0;34m(self, tokenizer, idata, raw_data, transform, pre_transform, filter_bn, flat_bn)\u001B[0m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mflat_bn \u001B[38;5;241m=\u001B[39m flat_bn\n\u001B[1;32m    168\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstats \u001B[38;5;241m=\u001B[39m get_dataset_stats(raw_data)\n\u001B[0;32m--> 169\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpd \u001B[38;5;241m=\u001B[39m \u001B[43mpad_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mraw_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstats\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflat_bn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mflat_bn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39midata \u001B[38;5;241m=\u001B[39m idata\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer \u001B[38;5;241m=\u001B[39m tokenizer\n",
      "File \u001B[0;32m~/cmatcher/cqa_search.py:112\u001B[0m, in \u001B[0;36mpad_dataset\u001B[0;34m(tokenizer, raw_data, stats, flat_bn)\u001B[0m\n\u001B[1;32m    109\u001B[0m ids1 \u001B[38;5;241m=\u001B[39m tokenizer(anchor_cqa, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    110\u001B[0m anchor_cqa \u001B[38;5;241m=\u001B[39m pad_seq(ids1, stats[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_len_cqa\u001B[39m\u001B[38;5;124m'\u001B[39m], pad_token\u001B[38;5;241m=\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39mpad_token_id)\n\u001B[0;32m--> 112\u001B[0m anchor_entities, anchor_entities_index \u001B[38;5;241m=\u001B[39m \u001B[43mpad_entities\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43manchor_graph\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstats\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_feature_len\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    113\u001B[0m \u001B[43m                                                      \u001B[49m\u001B[43mflat_bn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mflat_bn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    115\u001B[0m anchor_properties, anchor_properties_index \u001B[38;5;241m=\u001B[39m pad_entities(tokenizer, anchor_graph[\u001B[38;5;241m1\u001B[39m], stats[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_property_len\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    116\u001B[0m                                                           flat_bn\u001B[38;5;241m=\u001B[39mflat_bn)\n\u001B[1;32m    118\u001B[0m edge1 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mLongTensor(anchor_graph[\u001B[38;5;241m2\u001B[39m])\n",
      "File \u001B[0;32m~/cmatcher/cqa_search.py:89\u001B[0m, in \u001B[0;36mpad_entities\u001B[0;34m(tokenizer, entities, ml, flat_bn)\u001B[0m\n\u001B[1;32m     86\u001B[0m         n\u001B[38;5;241m.\u001B[39mappend(f)\n\u001B[1;32m     88\u001B[0m     ft[i] \u001B[38;5;241m=\u001B[39m sm[f]\n\u001B[0;32m---> 89\u001B[0m e1id \u001B[38;5;241m=\u001B[39m \u001B[43mtokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pad_seq(e1id, ml, pad_token\u001B[38;5;241m=\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39mpad_token_id), torch\u001B[38;5;241m.\u001B[39mLongTensor(ft)\n",
      "File \u001B[0;32m/projets/melodi/gsantoss/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2802\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.__call__\u001B[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m   2800\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_in_target_context_manager:\n\u001B[1;32m   2801\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_input_mode()\n\u001B[0;32m-> 2802\u001B[0m     encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_one\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext_pair\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtext_pair\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mall_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2803\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text_target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2804\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_target_mode()\n",
      "File \u001B[0;32m/projets/melodi/gsantoss/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2860\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase._call_one\u001B[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m   2857\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   2859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_valid_text_input(text):\n\u001B[0;32m-> 2860\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   2861\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2862\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2863\u001B[0m     )\n\u001B[1;32m   2865\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text_pair \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_valid_text_input(text_pair):\n\u001B[1;32m   2866\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   2867\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2868\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2869\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ontology_paths = {\n",
    "    'edas.owl': '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/edas.owl',\n",
    "    'ekaw.owl': '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/ekaw.owl',\n",
    "    'confOf.owl': '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/confOf.owl',\n",
    "    'conference.owl': '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/conference.owl',\n",
    "    'cmt.owl': '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/cmt.owl',\n",
    "}\n",
    "\n",
    "cqa_path = '/projets/melodi/gsantoss/data/complex/CQAs'\n",
    "entities_path = '/projets/melodi/gsantoss/data/complex/entities-cqas'\n",
    "\n",
    "if os.path.exists('/projets/melodi/gsantoss/tmp/idata.pkl'):\n",
    "    with open('/projets/melodi/gsantoss/tmp/idata.pkl', 'rb') as f:\n",
    "        train_ont_cqa_subg = dill.load(f)\n",
    "        print('loaded from cache.')\n",
    "else:\n",
    "    with open('/projets/melodi/gsantoss/tmp/idata.pkl', 'wb') as f:\n",
    "        dill.dump(load_entities(entities_path, ontology_paths), f)\n",
    "\n",
    "isg = load_sg(entities_path, ontology_paths)\n",
    "\n",
    "cqas = load_cqas(cqa_path)\n",
    "raw_data = build_raw_data(train_ont_cqa_subg, cqas)\n",
    "\n",
    "test_ont = config['test_ont']\n",
    "\n",
    "if os.path.exists(f'/projets/melodi/gsantoss/tmp/{test_ont}.pkl'):\n",
    "    with open(f'/projets/melodi/gsantoss/tmp/{test_ont}.pkl', 'rb') as f:\n",
    "        ifd, mc, mp, fres = dill.load(f)\n",
    "        print('loaded from cache.')\n",
    "else:\n",
    "    ifd, mc, mp, fres = build_raw_ts(f'/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/{test_ont}.owl',\n",
    "                                     isg[test_ont],\n",
    "                                     workers=4)\n",
    "    with open(f'/projets/melodi/gsantoss/tmp/{test_ont}.pkl', 'wb') as f:\n",
    "        dill.dump((ifd, mc, mp, fres), f)\n",
    "\n",
    "conts_cqa_subg = copy.deepcopy(train_ont_cqa_subg)\n",
    "del conts_cqa_subg[test_ont]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['language_model'])\n",
    "\n",
    "root_entities, graph_data, cq, cqid, caq, cqmask, tor = prepare_eval_dataset(test_ont, cqas, ifd, tokenizer, mc, mp,\n",
    "                                                                             fres, flat_bn=False)\n",
    "\n",
    "wandb.init(\n",
    "    project='tcmatcher',\n",
    "    config=config,\n",
    "    # group=f'{language_model}-{architecture}-{cpred}-{grad}',\n",
    "    settings=wandb.Settings(_disable_stats=True, _disable_meta=True)\n",
    ")\n",
    "\n",
    "print(config)\n",
    "\n",
    "# %%\n",
    "print('start training')\n",
    "\n",
    "# %%\n",
    "model = Model(config['language_model'], d=config['depth'], lm_grad=config['grad'] == 'grad')\n",
    "model.cuda(0)\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "def evm(model, dataset, th=0.5):\n",
    "    model.eval()\n",
    "\n",
    "    res = []\n",
    "    print('begin evm')\n",
    "    for batch in DataLoader(dataset, batch_size=2):\n",
    "        with torch.no_grad():\n",
    "            cqs, sbgs, _ = model(cqa=batch.cqs.cuda(0), positive_sbg=(batch.x_sf.cuda(0), batch.x_s.cuda(0),\n",
    "                                                                      batch.edge_index_s.cuda(0),\n",
    "                                                                      batch.edge_feat_sf.cuda(0),\n",
    "                                                                      batch.edge_feat_s.cuda(0)))\n",
    "\n",
    "            isbgs = sbgs[batch.rsi]\n",
    "\n",
    "            sim = torch.cosine_similarity(cqs, isbgs) > th\n",
    "            res.append(sim)\n",
    "\n",
    "    res = torch.cat(res, dim=0)\n",
    "    print('end evm')\n",
    "    return (res.sum() / res.size(0)).item()\n",
    "\n",
    "\n",
    "# model = Model(config['language_model'], d=config['depth'], lm_grad=config['grad'] == 'grad')\n",
    "\n",
    "# %%\n",
    "optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "lh = []\n",
    "evh = []\n",
    "epochs = config['epochs']\n",
    "batch_size = config['batch_size']\n",
    "progress = None\n",
    "\n",
    "triplet_loss = nn.TripletMarginWithDistanceLoss(\n",
    "    distance_function=lambda x, y: 1.0 - torch.cosine_similarity(x, y), margin=config['sim_margin'])\n",
    "\n",
    "print('build datasets')\n",
    "dataset = CQADataset(tokenizer, conts_cqa_subg, raw_data[test_ont], filter_bn=False, flat_bn=False)\n",
    "loader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "cqloader = DataLoader(cqid, batch_size=batch_size, shuffle=False)\n",
    "acqloader = [DataLoader(a, batch_size=batch_size, shuffle=False) for a in caq]\n",
    "graph_loader = DataLoader(graph_data, batch_size=batch_size, shuffle=False)\n",
    "# %%\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T16:23:48.081937Z",
     "start_time": "2024-03-11T16:23:40.242328Z"
    }
   },
   "id": "a21c08b1157d5bec",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print('data prepared')\n",
    "model.find_unused_parameters = False\n",
    "if not progress:\n",
    "    progress = tqdm(total=epochs * len(loader))\n",
    "\n",
    "print('start training')\n",
    "evh.append(evm(model, dataset, th=config[\"ev_sim_threshold\"]))\n",
    "eval_test(model, cqloader, graph_loader, cq, root_entities, fres, acqloader, cqmask, tor)\n",
    "wandb.log({'global/acc': evh[-1]})\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    el = []\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        cqs, sbgs, nsbg = model(cqa=batch.cqs.cuda(0), positive_sbg=(batch.x_sf.cuda(0), batch.x_s.cuda(0),\n",
    "                                                                     batch.edge_index_s.cuda(0),\n",
    "                                                                     batch.edge_feat_sf.cuda(0),\n",
    "                                                                     batch.edge_feat_s.cuda(0)),\n",
    "                                negative_sbg=(batch.x_nf.cuda(0), batch.x_n.cuda(0),\n",
    "                                              batch.edge_index_n.cuda(0), batch.edge_feat_nf.cuda(0),\n",
    "                                              batch.edge_feat_n.cuda(0)))\n",
    "\n",
    "        isbgs = sbgs[batch.rsi]\n",
    "        isbgn = nsbg[batch.rni]\n",
    "\n",
    "        loss = triplet_loss(cqs, isbgs, isbgn)\n",
    "        el.append(loss.detach())\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        progress.update(1)\n",
    "\n",
    "    lh.append(torch.stack(el).mean().item())\n",
    "\n",
    "    evh.append(evm(model, dataset, th=config[\"ev_sim_threshold\"]))\n",
    "    eval_test(model, cqloader, graph_loader, cq, root_entities, fres, acqloader, cqmask, tor)\n",
    "    wandb.log({'global/acc': evh[-1], 'global/loss': lh[-1]})\n",
    "\n",
    "progress.close()\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "torch.save(model.state_dict(), f'/projets/melodi/gsantoss/models/cmatcher.pt')\n",
    "# %%"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "821c08549cb27f3c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Model(\n  (emb1): BertEmb(\n    (bert): BertModel(\n      (embeddings): BertEmbeddings(\n        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n        (position_embeddings): Embedding(512, 768)\n        (token_type_embeddings): Embedding(2, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (encoder): BertEncoder(\n        (layer): ModuleList(\n          (0-11): 12 x BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (pooler): BertPooler(\n        (dense): Linear(in_features=768, out_features=768, bias=True)\n        (activation): Tanh()\n      )\n    )\n  )\n  (gnn): GNN(\n    (gnns): ModuleList()\n  )\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(config['language_model'], d=config['depth'], lm_grad=config['grad'] == 'grad')\n",
    "model.load_state_dict(torch.load(f'/projets/melodi/gsantoss/models/cmatcher.pt'))\n",
    "model.cuda(0)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T15:31:49.443695Z",
     "start_time": "2024-03-11T15:31:46.759672Z"
    }
   },
   "id": "c3c044987d8ccabc",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin evm\n",
      "end evm\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9438202381134033"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CQADataset(tokenizer, conts_cqa_subg, raw_data[test_ont], filter_bn=False)\n",
    "evm(model, dataset, th=config[\"ev_sim_threshold\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T15:34:52.057839Z",
     "start_time": "2024-03-11T15:31:49.444922Z"
    }
   },
   "id": "db98f1b0f896c4be",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'global/bt': 0.8, 'global/avgp': 1.0, 'global/rec': 1.0, 'global/afm': 1.0}\n",
      "{'global/gavgp': 0.6888581190051778, 'global/grec': 0.6382575757575757, 'global/gafm': 0.6600765654270265}\n"
     ]
    }
   ],
   "source": [
    "def eval_test(model, cqloader, graph_loader, cq, root_entities, res, caq, cqmask, tor):\n",
    "    model.eval()\n",
    "\n",
    "    cqeb = embed_cqas(model, cqloader)\n",
    "    aembs = [embed_cqas(model, a) for a in caq]\n",
    "\n",
    "    graph_embeddings = embed_subg(model, graph_loader)\n",
    "\n",
    "    avgps = []\n",
    "    rcs = []\n",
    "    fms = []\n",
    "\n",
    "    for t in torch.arange(0, 1, 0.05):\n",
    "        avgp, rc, fm = get_apr(eval_metrics(cq, cqeb, graph_embeddings, root_entities, res, th=t))\n",
    "        avgps.append(avgp)\n",
    "        rcs.append(rc)\n",
    "        fms.append(fm)\n",
    "\n",
    "    bv = torch.tensor(fms).argmax().item()\n",
    "\n",
    "    print({'global/bt': bv * 0.05, 'global/avgp': avgps[bv], 'global/rec': rcs[bv], 'global/afm': fms[bv]})\n",
    "\n",
    "    gavgps = 0\n",
    "    grcs = 0\n",
    "    gfms = 0\n",
    "\n",
    "    for i in range(len(tor)):\n",
    "        avgps = []\n",
    "        rcs = []\n",
    "        fms = []\n",
    "        for t in torch.arange(0, 1, 0.05):\n",
    "            metrics = eval_metrics(cq, aembs[i], graph_embeddings, root_entities, res, th=t,\n",
    "                                   cqm=[x[i] for x in cqmask])\n",
    "            avgp, rc, fm = get_apr(metrics)\n",
    "            avgps.append(avgp)\n",
    "            rcs.append(rc)\n",
    "            fms.append(fm)\n",
    "\n",
    "        bv = torch.tensor(fms).argmax().item()\n",
    "\n",
    "        gavgps += avgps[bv]\n",
    "        grcs += rcs[bv]\n",
    "        gfms += fms[bv]\n",
    "\n",
    "    gavgps /= len(tor)\n",
    "    grcs /= len(tor)\n",
    "    gfms /= len(tor)\n",
    "\n",
    "    print({'global/gavgp': gavgps, 'global/grec': grcs, 'global/gafm': gfms})\n",
    "    \n",
    "    \n",
    "    \n",
    "eval_test(model, cqloader, graph_loader, cq, root_entities, fres, acqloader, cqmask, tor)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:02:27.505289Z",
     "start_time": "2024-03-07T16:02:00.638213Z"
    }
   },
   "id": "5791a266885cee1c",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "795b15de77ce3cb7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "myenv",
   "language": "python",
   "display_name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
