{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-18T15:54:53.607754477Z",
     "start_time": "2023-11-18T15:54:53.595369349Z"
    }
   },
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "from rdflib.namespace import RDF, OWL\n",
    "from rdflib.term import BNode\n",
    "from cmatcher.owl_utils import load_entities, load_cqas, load_sg, add_depth, to_pyg\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader as TorchDataLoader\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.utils import degree\n",
    "from torch_geometric.loader import DataLoader\n",
    "from cmatcher.cqa_search import build_raw_data, build_graph_dataset, pad_seq, pad_entities, CQADataset, GraphData\n",
    "from torch_geometric.nn import MessagePassing\n",
    "# from cmatcher.eval_utils import prepare_eval_dataset, embed_cqas, embed_subg, eval_metrics\n",
    "from multiprocessing_on_dill import Pool\n",
    "from transformers import AutoTokenizer, BertModel, DistilBertModel, AutoModel\n",
    "import transformers.optimization as toptim\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "import dill\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import copy\n",
    "import torch_geometric.nn as gnn\n",
    "from torch_scatter import scatter_sum\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "import random\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T14:58:28.688183447Z",
     "start_time": "2023-11-18T14:58:28.681654296Z"
    }
   },
   "id": "1dde3c07b5aa97ed"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'edas.owl': '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/edas.owl',\n",
    "    'ekaw.owl': '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/ekaw.owl',\n",
    "    'confOf.owl': '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/confOf.owl',\n",
    "    'conference.owl': '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/Conference.owl',\n",
    "    'cmt.owl': '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/cmt.owl',\n",
    "}\n",
    "\n",
    "cqa_path = '/projets/melodi/gsantoss/data/complex/CQAs'\n",
    "entities_path = '/projets/melodi/gsantoss/data/complex/entities-cqas'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T14:58:28.719362444Z",
     "start_time": "2023-11-18T14:58:28.684197686Z"
    }
   },
   "id": "973951f08328093b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/101 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba585e8e59c748c9ab170f7a04183d1a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/101 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8fe3578c19e74323a727a2ed2e076231"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/101 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d8162a6569b49ba97cc2c03684dfe0b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "idata = load_entities(entities_path, paths)\n",
    "isg = load_sg(entities_path, paths)\n",
    "\n",
    "cqas = load_cqas(cqa_path)\n",
    "raw_data = build_raw_data(idata, cqas)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T14:59:06.489180582Z",
     "start_time": "2023-11-18T14:58:28.712448117Z"
    }
   },
   "id": "a2d90c9c05a990a6"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df8cbb6a201045949b6ead6052770d92"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d25c31894f66469486355a726058078b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2630d17f5a244d0b9ab45fa1df7bceab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2950fb6626e4549badc2a4722d7764b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T16:34:31.965236950Z",
     "start_time": "2023-11-18T16:34:29.106624996Z"
    }
   },
   "id": "3152b20c73d6c362"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from cache.\n"
     ]
    }
   ],
   "source": [
    "def sg_topg(s, ge, depth=4):\n",
    "    eg = Graph()\n",
    "    eg.add((s, RDF.type, OWL.Class))\n",
    "    add_depth(s, eg, ge, depth)\n",
    "    cm, pm, fm = to_pyg(s, eg)\n",
    "    return s, cm, pm, fm\n",
    "\n",
    "\n",
    "def build_raw_ts(op, data, workers=2):\n",
    "    ge = Graph().parse(op)\n",
    "\n",
    "    fres = {}\n",
    "    for k in data:\n",
    "        tn, ng = data[k]\n",
    "        fres[k] = tn\n",
    "        for t in ng:\n",
    "            ge.add(t)\n",
    "\n",
    "    mc = 0\n",
    "    mp = 0\n",
    "    ifd = []\n",
    "\n",
    "    subjects = set(ge.subjects())\n",
    "\n",
    "    with Pool(workers) as p:\n",
    "        pgs = list(tqdm(p.imap(lambda x: sg_topg(x, ge, depth=4), subjects), total=len(subjects)))\n",
    "\n",
    "    for s, cm, pm, fm in pgs:\n",
    "\n",
    "        mcc = max(map(len, cm))\n",
    "        mpc = max(map(len, pm))\n",
    "        if mcc > mc:\n",
    "            mc = mcc\n",
    "        if mpc > mp:\n",
    "            mp = mpc\n",
    "\n",
    "        ifd.append((s, cm, pm, fm))\n",
    "\n",
    "    return ifd, mc, mp, fres\n",
    "\n",
    "\n",
    "if os.path.exists('/projets/melodi/gsantoss/tmp/edas.pkl'):\n",
    "    with open('/projets/melodi/gsantoss/tmp/edas.pkl', 'rb') as f:\n",
    "        ifd, mc, mp, fres = dill.load(f)\n",
    "        print('loaded from cache.')\n",
    "else:\n",
    "    ifd, mc, mp, fres = build_raw_ts('/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/edas.owl', isg['edas'],\n",
    "                                    workers=6)\n",
    "    with open('/projets/melodi/gsantoss/tmp/edas.pkl', 'wb') as f:\n",
    "        dill.dump((ifd, mc, mp, fres), f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T16:34:39.203357760Z",
     "start_time": "2023-11-18T16:34:38.799849168Z"
    }
   },
   "id": "a4d6089cdd39b083"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "cidata = copy.deepcopy(idata)\n",
    "del cidata['edas']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T16:34:41.315100433Z",
     "start_time": "2023-11-18T16:34:41.281810907Z"
    }
   },
   "id": "6c49b601e536da02"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def clear_bn(ds):\n",
    "    new_dataset = []\n",
    "    for batch in ds:\n",
    "        ps = tokenizer.decode(batch.x_sf[batch.x_s][batch.rsi][0]).replace('[PAD]', '').strip()\n",
    "        if 'blank node' in ps or 'edas' in ps:\n",
    "            continue\n",
    "        \n",
    "        ns = tokenizer.decode(batch.x_nf[batch.x_n][batch.rni][0]).replace('[PAD]', '').strip()\n",
    "        \n",
    "        if 'blank node' in ns or 'edas' in ns:\n",
    "            continue\n",
    "            \n",
    "        new_dataset.append(batch)\n",
    "        \n",
    "    return new_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T16:34:41.475912073Z",
     "start_time": "2023-11-18T16:34:41.473538444Z"
    }
   },
   "id": "d2e1bfcc2a268841"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/524 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8357e492be7145b780f5b680cabaaf76"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "root_entities, graph_data, cq, cqid = prepare_eval_dataset(cqas['edas'], ifd, tokenizer, mc, mp)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T16:34:45.145486588Z",
     "start_time": "2023-11-18T16:34:43.051221588Z"
    }
   },
   "id": "a17c7cb4470bc722"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([70, 768])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class GNNL(gnn.MessagePassing):\n",
    "    def __init__(self, d_model, num_heads, drop=0.1):\n",
    "        super(GNNL, self).__init__(aggr='add')\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        self.ck = nn.Linear(2 * d_model, d_model)\n",
    "        \n",
    "        self.qw = nn.Linear(d_model, d_model)\n",
    "        self.vw = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.aw = nn.Sequential(\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(num_heads, num_heads)\n",
    "        )\n",
    "\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "        self.cw = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.lx = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.la = nn.Sequential(\n",
    "            nn.Linear(2 * d_model, d_model),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(d_model, 2),\n",
    "            nn.Softmax(dim=1),\n",
    "            nn.Dropout(drop)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        \n",
    "        q = self.qw(x[edge_index[1]])\n",
    "        k = self.ck(torch.cat([edge_attr, x[edge_index[0]]], dim=1))\n",
    "        \n",
    "        attention = self._attention(q, k, edge_index, x.shape[0]).unsqueeze(-1)\n",
    "        \n",
    "        h = self.propagate(edge_index, x=x, edge_attr=edge_attr, attention=attention)\n",
    "        \n",
    "        lx = self.lx(x)\n",
    "        \n",
    "        la = self.la(torch.cat([lx, h], dim=1))\n",
    "        \n",
    "        return x * la[:, 0].unsqueeze(-1) + h * la[:, 1].unsqueeze(-1)\n",
    "    \n",
    "    def _attention(self, q, k, ei, n):\n",
    "        \n",
    "        wq = self._reshape_mh(q)\n",
    "        wk = self._reshape_mh(k)\n",
    "        \n",
    "        aw = torch.einsum('bhd,bhq->bh', wq, wk) / math.sqrt(self.d_model)\n",
    "        a = torch.exp(self.aw(aw))\n",
    "        \n",
    "        sc = scatter_sum(a, ei[1], dim=0, dim_size=n)\n",
    "        \n",
    "        ad = sc[ei[1]]\n",
    "        ad[ad == 0] = 1\n",
    "        \n",
    "        return self.drop(a / ad)\n",
    "\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr, attention):\n",
    "        \n",
    "        v = self.vw(x_j)\n",
    "\n",
    "        wv = self._reshape_mh(v)\n",
    "    \n",
    "        fw = attention * wv\n",
    "        \n",
    "        return self.cw(self._reshape_out(fw))\n",
    "    \n",
    "    \n",
    "    def _reshape_mh(self, x):\n",
    "        return x.view(x.shape[0], self.num_heads, -1)\n",
    "\n",
    "    def _reshape_out(self, x):\n",
    "        return x.reshape(x.shape[0], self.d_model)\n",
    "    \n",
    "    \n",
    "    \n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, drop=0.1, d=3):\n",
    "        super(GNN, self).__init__()\n",
    "        self.gnns = nn.ModuleList([GNNL(d_model, num_heads, drop) for _ in range(d)])\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        for g in self.gnns:\n",
    "            x = g(x, edge_index, edge_attr)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "edge_index = torch.tensor([[0, 1, 2],\n",
    "                           [1, 1, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0.5], [-1]], dtype=torch.float)\n",
    "\n",
    "#torch.Size([70, 768]) torch.Size([2, 195]) torch.Size([195, 768])\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=torch.ones((2, 1)))\n",
    "\n",
    "g = GNNL(768, 4)\n",
    "\n",
    "out = g(torch.randn(70, 768), torch.randint(0, 70, (2, 195)), torch.randn(195, 768))\n",
    "# out = g(x, edge_index, torch.ones((2, 1)))\n",
    "# print(out)\n",
    "print(out.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T16:34:47.370009271Z",
     "start_time": "2023-11-18T16:34:47.274605249Z"
    }
   },
   "id": "4afec310e98c5e8d"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    \n",
    "class BertEmb(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertEmb, self).__init__()\n",
    "        # self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        # self.bert = BertModel.from_pretrained('bert-large-uncased')\n",
    "        self.bert = AutoModel.from_pretrained(\"roberta-base\")\n",
    "        self.bert.pooler.requires_grad_(False)\n",
    "        # self.bert.gradient_checkpointing_enable()\n",
    "    def forward(self, x):\n",
    "        mask = x > 0\n",
    "        out = self.bert(input_ids=x, attention_mask=mask)['last_hidden_state']\n",
    "\n",
    "        om = mask.unsqueeze(-1).float()\n",
    "\n",
    "        mo = out * om\n",
    "        cf = om.sum(dim=1)\n",
    "        cf[cf == 0] = 1\n",
    "        return mo.sum(dim=1) / cf\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.emb1 = BertEmb()\n",
    "        self.gnn = GNN(768, 8, d=4)\n",
    "\n",
    "\n",
    "    def forward(self, cqa=None, positive_sbg=None, negative_sbg=None):\n",
    "        \n",
    "        if cqa is not None:\n",
    "            cqa = self.embed_cqa(cqa)\n",
    "\n",
    "        sbg = None\n",
    "        \n",
    "        if positive_sbg is not None:\n",
    "            x, xi, edge_index, edge_attr, edge_attr_i = positive_sbg\n",
    "\n",
    "            sbg = self.embed_subg(x, xi, edge_index, edge_attr, edge_attr_i)\n",
    "        nsbg = None\n",
    "        \n",
    "        if negative_sbg is not None:\n",
    "            nx, nxi, nedge_index, nedge_attr, nedge_attr_i = negative_sbg\n",
    "            nsbg = self.embed_subg(nx, nxi, nedge_index, nedge_attr, nedge_attr_i)\n",
    "\n",
    "        return cqa, sbg, nsbg\n",
    "\n",
    "    def embed_cqa(self, x):\n",
    "        return self.emb1(x)\n",
    "\n",
    "    def embed_subg(self, x, xi, edge_index, edge_attr, edge_attr_i):\n",
    "        feats = []\n",
    "        for f in TorchDataLoader(x, batch_size=4, shuffle=False):\n",
    "            feats.append(checkpoint.checkpoint(self.emb1, f, use_reentrant=False))\n",
    "        feats = torch.cat(feats, dim=0)\n",
    "        sf = feats[xi]\n",
    "        \n",
    "        props = []\n",
    "        for f in TorchDataLoader(edge_attr, batch_size=4, shuffle=False):\n",
    "            props.append(checkpoint.checkpoint(self.emb1, f, use_reentrant=False))\n",
    "        props = torch.cat(props, dim=0)\n",
    "        edge_attr_sf = props[edge_attr_i]\n",
    "        \n",
    "        out = checkpoint.checkpoint(self.gnn, sf, edge_index, edge_attr_sf, use_reentrant=False)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = Model()\n",
    "device = torch.device('cuda:0')\n",
    "# model.cuda(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T16:35:39.829768202Z",
     "start_time": "2023-11-18T16:35:38.424842977Z"
    }
   },
   "id": "d163d47c5ef7cd04"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/728 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5e3c2726006405e984cd6a2f70b6110"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First evaluation:\n",
      "bt: 0.55 avgp: 0.29, rec: 0.04, afm: 0.07\n",
      "ev data: 0.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 119\u001B[0m\n\u001B[1;32m    116\u001B[0m         ax[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mplot(evh)\n\u001B[1;32m    117\u001B[0m         plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[0;32m--> 119\u001B[0m \u001B[43mnotebook_launcher\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_function\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mroot_entities\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgraph_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcqid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfres\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_processes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_port\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m29502\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/projets/melodi/gsantoss/miniconda3/envs/myenv/lib/python3.11/site-packages/accelerate/launchers.py:175\u001B[0m, in \u001B[0;36mnotebook_launcher\u001B[0;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes)\u001B[0m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLaunching training on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_processes\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m GPUs.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 175\u001B[0m     \u001B[43mstart_processes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlauncher\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnprocs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_processes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfork\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ProcessRaisedException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m e\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;241m0\u001B[39m]:\n",
      "File \u001B[0;32m/projets/melodi/gsantoss/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:202\u001B[0m, in \u001B[0;36mstart_processes\u001B[0;34m(fn, args, nprocs, join, daemon, start_method)\u001B[0m\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m context\n\u001B[1;32m    201\u001B[0m \u001B[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001B[39;00m\n\u001B[0;32m--> 202\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    203\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m/projets/melodi/gsantoss/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:114\u001B[0m, in \u001B[0;36mProcessContext.join\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;66;03m# Wait for any process to fail or all of them to succeed.\u001B[39;00m\n\u001B[0;32m--> 114\u001B[0m ready \u001B[38;5;241m=\u001B[39m \u001B[43mmultiprocessing\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    115\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msentinels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeys\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    116\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    117\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    119\u001B[0m error_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sentinel \u001B[38;5;129;01min\u001B[39;00m ready:\n",
      "File \u001B[0;32m/projets/melodi/gsantoss/miniconda3/envs/myenv/lib/python3.11/multiprocessing/connection.py:947\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    944\u001B[0m     deadline \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic() \u001B[38;5;241m+\u001B[39m timeout\n\u001B[1;32m    946\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 947\u001B[0m     ready \u001B[38;5;241m=\u001B[39m \u001B[43mselector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    948\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ready:\n\u001B[1;32m    949\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [key\u001B[38;5;241m.\u001B[39mfileobj \u001B[38;5;28;01mfor\u001B[39;00m (key, events) \u001B[38;5;129;01min\u001B[39;00m ready]\n",
      "File \u001B[0;32m/projets/melodi/gsantoss/miniconda3/envs/myenv/lib/python3.11/selectors.py:415\u001B[0m, in \u001B[0;36m_PollLikeSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    413\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    414\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 415\u001B[0m     fd_event_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_selector\u001B[38;5;241m.\u001B[39mpoll(timeout)\n\u001B[1;32m    416\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n\u001B[1;32m    417\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ready\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def sim_loss(cq, pe, ne):\n",
    "    return torch.mean(1 - torch.cosine_similarity(cq, pe) + torch.cosine_similarity(cq, ne))\n",
    "\n",
    "def evm(accelerator, model, dataset, th=0.5):\n",
    "    model.eval()\n",
    "\n",
    "    res = []\n",
    "    for batch in DataLoader(dataset, batch_size=2):\n",
    "        with torch.no_grad():\n",
    "\n",
    "            cqs, sbgs, _ = model(cqa=batch.cqs, positive_sbg=(batch.x_sf, batch.x_s,\n",
    "                              batch.edge_index_s, batch.edge_feat_sf, batch.edge_feat_s))\n",
    "\n",
    "            isbgs = sbgs[batch.rsi]\n",
    "\n",
    "            sim = torch.cosine_similarity(cqs, isbgs) > th\n",
    "            res.append(accelerator.gather_for_metrics(sim))\n",
    "            \n",
    "\n",
    "    res = torch.cat(res, dim=0)\n",
    "\n",
    "    return (res.sum() / res.size(0)).item()\n",
    "\n",
    "\n",
    "def eval_test(accelerator, model, cqloader, graph_loader, cq, root_entities, res):\n",
    "    model.eval()\n",
    "\n",
    "    cqeb = embed_cqas(accelerator, model, cqloader)\n",
    "    graph_embeddings = embed_subg(accelerator, model, graph_loader)\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        avgps = []\n",
    "        rcs = []\n",
    "        fms = []\n",
    "    \n",
    "        for t in torch.arange(0, 1, 0.05):\n",
    "            avgp, rc, fm = eval_metrics(cq, cqeb, graph_embeddings, root_entities, res, th=t)\n",
    "            avgps.append(avgp)\n",
    "            rcs.append(rc)\n",
    "            fms.append(fm)\n",
    "    \n",
    "        bv = torch.tensor(fms).argmax().item()\n",
    "        accelerator.print(f'bt: {bv * 0.05:.2f} avgp: {avgps[bv]:.2f}, rec: {rcs[bv]:.2f}, afm: {fms[bv]:.2f}')\n",
    "\n",
    "\n",
    "def train_function(model, root_entities, graph_data, cq, cqid, res):\n",
    "\n",
    "    accelerator = Accelerator(gradient_accumulation_steps=4, mixed_precision='fp16')\n",
    "    # optimizer = optim.AdamW(model.parameters(), lr=0.00001)\n",
    "    optimizer = toptim.Adafactor(model.parameters())\n",
    "    model\n",
    "    \n",
    "    lh = []\n",
    "    evh = []\n",
    "    epochs = 8\n",
    "    batch_size = 2\n",
    "    progress = None\n",
    "    \n",
    "    dataset = CQADataset(tokenizer, cidata, raw_data['edas'])\n",
    "    loader = DataLoader(dataset, batch_size=batch_size)\n",
    "    \n",
    "    \n",
    "    cqloader = DataLoader(cqid, batch_size=batch_size, shuffle=False)\n",
    "    graph_loader = DataLoader(graph_data, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model, optimizer, loader, cqloader, graph_loader = accelerator.prepare(model, optimizer, loader, cqloader, graph_loader)\n",
    "    \n",
    "    \n",
    "    if not progress and accelerator.is_main_process:\n",
    "        progress = tqdm(total=epochs * len(loader))\n",
    "\n",
    "    accelerator.print('First evaluation:')\n",
    "    eval_test(accelerator, model, cqloader, graph_loader, cq, root_entities, res)\n",
    "    accelerator.print(f'ev data: {evm(accelerator, model, dataset, th=0.9):.2f}')\n",
    "    \n",
    "    for e in range(epochs):\n",
    "    \n",
    "        model.train()\n",
    "        \n",
    "        el = []\n",
    "        for batch in loader:\n",
    "            with accelerator.accumulate(model):\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "\n",
    "                \n",
    "                cqs, sbgs, nsbg = model(cqa=batch.cqs, positive_sbg=(batch.x_sf, batch.x_s,\n",
    "                              batch.edge_index_s, batch.edge_feat_sf, batch.edge_feat_s), negative_sbg=(batch.x_nf, batch.x_n,\n",
    "                               batch.edge_index_n, batch.edge_feat_nf, batch.edge_feat_n))\n",
    "                    \n",
    "\n",
    "                isbgs = sbgs[batch.rsi]\n",
    "                isbgn = nsbg[batch.rni]\n",
    "        \n",
    "                loss = sim_loss(cqs, isbgs, isbgn)\n",
    "                el.append(accelerator.gather_for_metrics(loss.detach()))\n",
    "                accelerator.backward(loss)\n",
    "        \n",
    "                optimizer.step()\n",
    "                if accelerator.is_main_process:\n",
    "                    progress.update(1)\n",
    "                \n",
    "        lh.append(torch.stack(el).mean().item())\n",
    "\n",
    "        evh.append(evm(accelerator, model, dataset, th=0.9))\n",
    "        eval_test(accelerator, model, cqloader, graph_loader, cq, root_entities, res)\n",
    "        accelerator.print(f'epoch {e} loss: {lh[-1]:.2f}, ev: {evh[-1]:.2f}')\n",
    "    \n",
    "    \n",
    "    if accelerator.is_main_process:\n",
    "        progress.close()\n",
    "    \n",
    "        fig, ax = plt.subplots(1, 2)\n",
    "        fig.tight_layout()\n",
    "        ax[0].plot(lh)\n",
    "        ax[1].plot(evh)\n",
    "        plt.show()\n",
    "\n",
    "notebook_launcher(train_function, (model, root_entities, graph_data, cq, cqid, fres), num_processes=2, use_port='29502')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T16:43:56.163575457Z",
     "start_time": "2023-11-18T16:35:39.843738282Z"
    }
   },
   "id": "81cd16f8861a744f"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m fms \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m torch\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0.05\u001B[39m):\n\u001B[0;32m----> 6\u001B[0m     avgp, rc, fm \u001B[38;5;241m=\u001B[39m \u001B[43meval_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcqeb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgraph_embeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mroot_entities\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mres\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m     avgps\u001B[38;5;241m.\u001B[39mappend(avgp)\n\u001B[1;32m      8\u001B[0m     rcs\u001B[38;5;241m.\u001B[39mappend(rc)\n",
      "Cell \u001B[0;32mIn[23], line 92\u001B[0m, in \u001B[0;36meval_metrics\u001B[0;34m(cqa_list, cqa_embeddings, fe, ts, res, th)\u001B[0m\n\u001B[1;32m     88\u001B[0m metrics \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m cqa_name, e \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(cqa_list, cqa_embeddings):\n\u001B[0;32m---> 92\u001B[0m     sim \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcosine_similarity\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m     resid \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mwhere(sim \u001B[38;5;241m>\u001B[39m th)[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m     94\u001B[0m     rs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plt.plot(avgps, label='avgp')\n",
    "# plt.plot(rcs, label='rc')\n",
    "# plt.plot(fms, label='fm')\n",
    "# plt.legend()\n",
    "# # verical line on max fm\n",
    "# plt.axvline(x=bv, color='black', linestyle='--')\n",
    "# \n",
    "# plt.show()\n",
    "# \n",
    "# print(f'best threshold: {bv * 0.05:.2f}')\n",
    "# print(f'avgp: {avgps[bv]:.2f}, rec: {rcs[bv]:.2f}, afm: {fms[bv]:.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:48:14.123683516Z",
     "start_time": "2023-11-17T09:48:13.803976416Z"
    }
   },
   "id": "46fb604297f890e7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "myenv",
   "language": "python",
   "display_name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
