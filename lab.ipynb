{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:04:29.877408758Z",
     "start_time": "2023-10-25T17:04:24.768957261Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projets/melodi/gsantoss/miniconda3/envs/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "from rdflib import Graph, URIRef, BNode\n",
    "from rdflib.namespace import RDF, RDFS, OWL\n",
    "from om.ont import get_namespace, get_n\n",
    "from cmatcher.owl_utils import load_entities, load_cqas, load_sg, add_depth, to_pyg\n",
    "from termcolor import colored\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader as TorchDataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from cmatcher.cqa_search import build_raw_data, build_graph_dataset, pad_seq\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from multiprocessing_on_dill import Pool\n",
    "from transformers import AutoTokenizer, BertModel\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:04:29.910833074Z",
     "start_time": "2023-10-25T17:04:29.878398513Z"
    }
   },
   "id": "1dde3c07b5aa97ed"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'edas.owl': '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/edas.owl',\n",
    "    'ekaw.owl': '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/ekaw.owl',\n",
    "    'confOf.owl': '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/confOf.owl',\n",
    "    'conference.owl': '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/Conference.owl',\n",
    "    'cmt.owl': '/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/cmt.owl',\n",
    "}\n",
    "\n",
    "cqa_path = '/projets/melodi/gsantoss/data/complex/CQAs'\n",
    "entities_path = '/projets/melodi/gsantoss/data/complex/entities-cqas'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:04:29.911449674Z",
     "start_time": "2023-10-25T17:04:29.882151812Z"
    }
   },
   "id": "973951f08328093b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:30<00:00,  3.28it/s]\n",
      "100%|██████████| 101/101 [00:00<00:00, 194.47it/s]\n",
      "100%|██████████| 101/101 [00:00<00:00, 952.58it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "idata = load_entities(entities_path, paths)\n",
    "isg = load_sg(entities_path, paths)\n",
    "\n",
    "cqas = load_cqas(cqa_path)\n",
    "raw_data = build_raw_data(idata, cqas)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:05:01.517277564Z",
     "start_time": "2023-10-25T17:04:29.901753563Z"
    }
   },
   "id": "a2d90c9c05a990a6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:05:01.915402033Z",
     "start_time": "2023-10-25T17:05:01.502133424Z"
    }
   },
   "id": "3152b20c73d6c362"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "dataset = build_graph_dataset(tokenizer, cqas, idata, raw_data['edas'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:05:11.358891426Z",
     "start_time": "2023-10-25T17:05:01.918822429Z"
    }
   },
   "id": "63fed4a37ab9b07d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 524/524 [03:00<00:00,  2.91it/s]\n"
     ]
    }
   ],
   "source": [
    "def sg_topg(s, ge, depth=4):\n",
    "    eg = Graph()\n",
    "    eg.add((s, RDF.type, OWL.Class))\n",
    "    add_depth(s, eg, ge, depth)\n",
    "    cm, pm, fm = to_pyg(s, eg)\n",
    "    return s, cm, pm, fm\n",
    "\n",
    "\n",
    "def build_raw_ts(op, data):\n",
    "    ge = Graph().parse(op)\n",
    "\n",
    "    res = {}\n",
    "    for k in data:\n",
    "        tn, ng = data[k]\n",
    "        res[k] = tn\n",
    "        for t in ng:\n",
    "            ge.add(t)\n",
    "\n",
    "    mc = 0\n",
    "    mp = 0\n",
    "    ifd = []\n",
    "    \n",
    "    subjects = set(ge.subjects())\n",
    "    \n",
    "    with Pool(6) as p:\n",
    "        pgs = list(tqdm(p.imap(lambda x: sg_topg(x, ge, depth=4), subjects), total=len(subjects)))\n",
    "    \n",
    "    for s, cm, pm, fm in pgs:\n",
    "\n",
    "        mcc = max(map(len, cm))\n",
    "        mpc = max(map(len, pm))\n",
    "        if mcc > mc:\n",
    "            mc = mcc\n",
    "        if mpc > mp:\n",
    "            mp = mpc\n",
    "\n",
    "        ifd.append((s, cm, pm, fm))\n",
    "\n",
    "    return ifd, mc, mp, res\n",
    "\n",
    "ifd, mc, mp, res = build_raw_ts('/projets/melodi/gsantoss/data/oaei/tracks/conference/onts/edas.owl', isg['edas'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T13:48:38.465539164Z",
     "start_time": "2023-10-25T13:45:37.893223531Z"
    }
   },
   "id": "a4d6089cdd39b083"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class GNN(MessagePassing):\n",
    "    def __init__(self):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "\n",
    "    def forward(self, x, edge_index, edge_features):\n",
    "\n",
    "        # Step 4-5: Start propagating messages.\n",
    "        out = self.propagate(edge_index, x=x, ef=edge_features)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, ef):\n",
    "        return x_j * ef\n",
    "    \n",
    "\n",
    "gnn = GNN()\n",
    "\n",
    "edge_index = torch.LongTensor([[1, 2],\n",
    "                           [0, 0]])\n",
    "edge_features = torch.Tensor([[0.5], [1.0]])\n",
    "x = torch.Tensor([[1], [2], [3]])\n",
    "\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_features)\n",
    "out = gnn(data.x, data.edge_index, data.edge_attr)\n",
    "print(out)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T13:48:38.470515070Z",
     "start_time": "2023-10-25T13:48:38.462426639Z"
    }
   },
   "id": "7cb9afb55c77b360"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "DataParallel(\n  (module): Model(\n    (emb): BerdEmb(\n      (bert): BertModel(\n        (embeddings): BertEmbeddings(\n          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n          (position_embeddings): Embedding(512, 768)\n          (token_type_embeddings): Embedding(2, 768)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (encoder): BertEncoder(\n          (layer): ModuleList(\n            (0-11): 12 x BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n        (pooler): BertPooler(\n          (dense): Linear(in_features=768, out_features=768, bias=True)\n          (activation): Tanh()\n        )\n      )\n    )\n  )\n)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class BerdEmb(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BerdEmb, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = x > 0\n",
    "        out = self.bert(input_ids=x, attention_mask=mask)['last_hidden_state']\n",
    "        om =  mask.unsqueeze(-1).float()\n",
    "        mo = out * om\n",
    "        return mo.sum(dim=1) / om.sum(dim=1)\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.emb = BerdEmb()\n",
    "\n",
    "    def forward(self, cqa, x, edge_index, edge_attr):\n",
    "        cqa = self.embed_cqa(cqa)\n",
    "        sbg = self.embed_subg(x, edge_index, edge_attr)\n",
    "        return cqa, sbg\n",
    "    \n",
    "    def embed_cqa(self, x):\n",
    "        return self.emb(x)\n",
    "    \n",
    "    def embed_subg(self, x, edge_index, edge_attr):\n",
    "        feats = []\n",
    "        for f in TorchDataLoader(x, batch_size=8, shuffle=False):\n",
    "            if self.training:\n",
    "                feats.append(checkpoint.checkpoint(self.emb, f, use_reentrant=False))\n",
    "            else:\n",
    "                feats.append(self.emb(f))\n",
    "        feats = torch.cat(feats, dim=0)\n",
    "        \n",
    "        return feats\n",
    "    \n",
    "    \n",
    "gnn = GNN()\n",
    "model = Model()\n",
    "model = nn.DataParallel(model)\n",
    "model.cuda(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T13:54:41.052838949Z",
     "start_time": "2023-10-25T13:54:39.336010530Z"
    }
   },
   "id": "d163d47c5ef7cd04"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "triplet_loss = nn.TripletMarginWithDistanceLoss(margin=0.5, distance_function=lambda x, y: 0.5 - nn.functional.cosine_similarity(x, y))\n",
    "cossine_loss = nn.CosineSimilarity()\n",
    "\n",
    "def evm(model, dataset, th=0.5):\n",
    "    model.eval()\n",
    "    \n",
    "    res = []\n",
    "    for batch in DataLoader(dataset, batch_size=4):\n",
    "        with torch.no_grad():\n",
    "            cqs, sbgs = model(batch.cqs.cuda(0), batch.x_s.cuda(0), batch.edge_index_s.cuda(0), batch.edge_feat_s.cuda(0))\n",
    "            isbgs = sbgs[batch.rsi]\n",
    "            \n",
    "            \n",
    "            sim = torch.cosine_similarity(cqs, isbgs) > th\n",
    "            res.append(sim)\n",
    "            \n",
    "    res = torch.cat(res, dim=0)\n",
    "    \n",
    "    return (res.sum() / res.size(0)).item()\n",
    "            \n",
    "\n",
    "lh = []\n",
    "evh = []\n",
    "epochs = 5\n",
    "batch_size = 2\n",
    "progress = None\n",
    "for e in range(epochs):\n",
    "    dataset = build_graph_dataset(tokenizer, cqas, idata, raw_data['edas'])\n",
    "    if not progress:\n",
    "        progress = tqdm(total=epochs * math.ceil(len(dataset) / batch_size))\n",
    "    evh.append(evm(model, dataset))\n",
    "    model.train()\n",
    "    el = []\n",
    "    for batch in DataLoader(dataset, batch_size=batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        cqs, sbgs = model(batch.cqs.cuda(0), batch.x_s.cuda(0), batch.edge_index_s.cuda(0), batch.edge_feat_s.cuda(0))\n",
    "        isbgs = sbgs[batch.rsi]\n",
    "        \n",
    "        cqap, sbgp = model(batch.cqp.cuda(0), batch.x_p.cuda(0), batch.edge_index_p.cuda(0), batch.edge_feat_p.cuda(0))\n",
    "        isbgp = sbgp[batch.rpi]\n",
    "        \n",
    "        cqan, sbgn = model(batch.cqn.cuda(0), batch.x_n.cuda(0), batch.edge_index_n.cuda(0), batch.edge_feat_n.cuda(0))\n",
    "        isbgn = sbgn[batch.rni]\n",
    "        \n",
    "        loss1 = triplet_loss(cqs, cqap, cqan)\n",
    "        loss2 = triplet_loss(isbgs, isbgp, isbgn)\n",
    "        loss3 = cossine_loss(cqs, isbgs).mean()\n",
    "        \n",
    "        loss = loss1 + loss2 + loss3\n",
    "        el.append(loss.item())\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        progress.update(1)\n",
    "    \n",
    "    lh.append(sum(el) / len(el))\n",
    "\n",
    "\n",
    "progress.close()\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.tight_layout()\n",
    "ax[0].plot(lh)\n",
    "ax[1].plot(evh)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9300e37871cadd48"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "dataset = build_graph_dataset(tokenizer, cqas, idata, raw_data['edas'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T13:49:37.084442849Z",
     "start_time": "2023-10-25T13:49:27.774260037Z"
    }
   },
   "id": "88626018d99f49d9"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] select distinct? s? o where {? s < http : / / conference # has _ important _ dates >? o2.? o2 < http : / / conference # is _ an _ ending _ date >? o. } [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS] http : / / conference # is _ an _ ending _ date [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "r = []\n",
    "for batch in DataLoader(dataset, batch_size=2):\n",
    "    print(tokenizer.decode(batch.cqs[0]))\n",
    "    print(tokenizer.decode(batch.x_s[1]))\n",
    "    \n",
    "\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T15:16:40.432955153Z",
     "start_time": "2023-10-25T15:16:40.407211942Z"
    }
   },
   "id": "1b5ba3db70748077"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 524/524 [00:13<00:00, 39.05it/s]\n",
      "100%|██████████| 262/262 [02:31<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "class IData(Data):\n",
    "    def __inc__(self, key, value, *args, **kwargs):\n",
    "        if key == 'rsi':\n",
    "            return self.x_s.size(0)\n",
    "\n",
    "        if key == 'edge_index_s':\n",
    "            return self.x_s.size(0)\n",
    "\n",
    "        return super().__inc__(key, value, *args, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "def embed_subg(model, ifd, tokenizer, mc, mp):\n",
    "    model.eval()\n",
    "    ts = []\n",
    "    graph_data = []\n",
    "    for s, cm, pm, fm in tqdm(ifd):\n",
    "        e1id = tokenizer(cm, return_tensors='pt', padding=True)['input_ids']\n",
    "        pd1 = pad_seq(e1id, mc)\n",
    "        pd1 = torch.cat([torch.zeros((1, mc)), pd1], dim=0)\n",
    "\n",
    "        e1pid = tokenizer(pm, return_tensors='pt', padding=True)['input_ids']\n",
    "        pd3 = pad_seq(e1pid, mp)\n",
    "\n",
    "        edge1 = torch.LongTensor(fm)\n",
    "\n",
    "        ts.append(s)\n",
    "        graph_data.append(IData(rsi=torch.LongTensor([1]), x_s=pd1.long(), edge_index_s=edge1, edge_feat_s=pd3))\n",
    "\n",
    "    fe = []\n",
    "    for batch in tqdm(DataLoader(graph_data, batch_size=2, shuffle=False)):\n",
    "        with torch.no_grad():\n",
    "            out = model.embed_subg(batch.x_s.cuda(0), batch.edge_index_s, batch.edge_feat_s)\n",
    "            fe.append(out[batch.rsi])\n",
    "\n",
    "    fe = torch.cat(fe, dim=0)\n",
    "\n",
    "    return ts, fe\n",
    "\n",
    "model = model.module.cuda(0)\n",
    "root_entities, graph_embeddings = embed_subg(model, ifd, tokenizer, mc, mp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T13:57:30.997966880Z",
     "start_time": "2023-10-25T13:54:45.679910348Z"
    }
   },
   "id": "d1228e4163fe8c56"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def embed_cqas(model, data, tokenizer):\n",
    "    model.eval()\n",
    "    cq = []\n",
    "    cqi = []\n",
    "    for k in data:\n",
    "        cq.append(k)\n",
    "        cqi.append(data[k])\n",
    "    \n",
    "    cqid = tokenizer(cqi, return_tensors='pt', padding=True)['input_ids']\n",
    "    \n",
    "    cqeb = []\n",
    "    \n",
    "    for c in DataLoader(cqid, batch_size=2, shuffle=False):\n",
    "        with torch.no_grad():\n",
    "            out = model.embed_cqa(c.cuda(0))            \n",
    "            cqeb.append(out)\n",
    "        \n",
    "    cqeb = torch.cat(cqeb, dim=0)\n",
    "    return cq, cqeb\n",
    "\n",
    "\n",
    "cq, cqeb = embed_cqas(model, cqas['edas'], tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T13:57:31.334459854Z",
     "start_time": "2023-10-25T13:57:30.990043302Z"
    }
   },
   "id": "f346c0e3cf3960ab"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avgp: 1.00, rec: 0.00, afm: 0.00\n"
     ]
    }
   ],
   "source": [
    "def eval_metrics(cqa_list, cqa_embeddings, fe, ts, res, th=0.8):\n",
    "    metrics = []\n",
    "\n",
    "    for cqa_name, e in zip(cqa_list, cqa_embeddings):\n",
    "        sim = torch.cosine_similarity(e.unsqueeze(0), fe, dim=1)\n",
    "        resid = torch.where(sim > th)[0]\n",
    "        rs = set()\n",
    "        for r in resid:\n",
    "            rs.add(ts[r.item()])\n",
    "        metrics.append((1 if res[cqa_name] in rs else 0, len(rs)))\n",
    "\n",
    "    rc = sum([m[0] for m in metrics]) / len(metrics)\n",
    "    avgp = sum([1 / m[1] if m[1] > 0 else 0 for m in metrics]) / len(metrics)\n",
    "    fm = 2 * rc * avgp / (rc + avgp) if rc + avgp > 0 else 0\n",
    "    return rc, avgp, fm\n",
    "\n",
    "avgp, rc, fm = eval_metrics(cq, cqeb, graph_embeddings, root_entities, res, th=0.5)\n",
    "print(f'avgp: {avgp:.2f}, rec: {rc:.2f}, afm: {fm:.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T13:57:31.617134791Z",
     "start_time": "2023-10-25T13:57:31.337260741Z"
    }
   },
   "id": "46fb604297f890e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-25T11:00:21.343505156Z"
    }
   },
   "id": "376d01542ff89fa4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "myenv",
   "language": "python",
   "display_name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
